{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoseEstimator(object):\n",
    "    def __init__(self):\n",
    "        # Use locality sensitive hashing algorithm\n",
    "        flann_params = dict(algorithm=6, table_number=6, key_size=12, multi_probe_level=1)\n",
    "        self.min_matches = 10\n",
    "        self.cur_target = namedtuple('Current', 'image, rect, keypoints, descriptors, data')\n",
    "        self.tracked_target = namedtuple('Tracked', 'target, points_prev, points_cur, H, quad')\n",
    "\n",
    "        self.feature_detector = cv2.ORB_create()\n",
    "        self.feature_detector.setMaxFeatures(1000)\n",
    "        self.feature_matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "        self.tracking_targets = []\n",
    "\n",
    "    # Function to add a new target for tracking\n",
    "    def add_target(self, image, rect, data=None):\n",
    "        x_start, y_start, x_end, y_end = rect\n",
    "        keypoints, descriptors = [], []\n",
    "        for keypoint, descriptor in zip(*self.detect_features(image)):\n",
    "            x, y = keypoint.pt\n",
    "            if x_start <= x <= x_end and y_start <= y <= y_end:\n",
    "                keypoints.append(keypoint)\n",
    "                descriptors.append(descriptor)\n",
    "\n",
    "        descriptors = np.array(descriptors, dtype='uint8')\n",
    "        self.feature_matcher.add([descriptors])\n",
    "        target = self.cur_target(image=image, rect=rect, keypoints=keypoints, descriptors=descriptors, data=None)\n",
    "        self.tracking_targets.append(target)\n",
    "\n",
    "    # To get a list of detected objects\n",
    "    def track_target(self, frame):\n",
    "        self.cur_keypoints, self.cur_descriptors = self.detect_features(frame)\n",
    "\n",
    "        if len(self.cur_keypoints) < self.min_matches: return []\n",
    "        try: matches = self.feature_matcher.knnMatch(self.cur_descriptors, k=2)\n",
    "        except Exception:\n",
    "            print('Invalid target, please select another with features to extract')\n",
    "            return []\n",
    "        \n",
    "        matches = [m[0] for m in matches if len(m) == 2 and m[0].distance < m[1].distance * 0.75]\n",
    "        if len(matches) < self.min_matches: return []\n",
    "\n",
    "        matches_using_index = [[] for _ in range(len(self.tracking_targets))]\n",
    "        for match in matches:\n",
    "            matches_using_index[match.imgIdx].append(match)\n",
    "\n",
    "        tracked = []\n",
    "        for image_index, matches in enumerate(matches_using_index):\n",
    "            if len(matches) < self.min_matches: continue\n",
    "\n",
    "            target = self.tracking_targets[image_index]\n",
    "            points_prev = [target.keypoints[m.trainIdx].pt for m in matches]\n",
    "            points_cur = [self.cur_keypoints[m.queryIdx].pt for m in matches]\n",
    "            points_prev, points_cur = np.float32((points_prev, points_cur))\n",
    "            H, status = cv2.findHomography(points_prev, points_cur, cv2.RANSAC, 3.0)\n",
    "            status = (status.ravel() != 0)\n",
    "\n",
    "            if status.sum() < self.min_matches: continue\n",
    "\n",
    "            points_prev, points_cur = points_prev[status], points_cur[status]\n",
    "\n",
    "            x_start, y_start, x_end, y_end = target.rect\n",
    "            \n",
    "            quad = np.float32([[x_start, y_start], [x_end, y_start], [x_end, y_end], [x_start, y_end]])\n",
    "            quad = cv2.perspectiveTransform(quad.reshape(1, -1, 2), H).reshape(-1, 2)\n",
    "            \n",
    "            track = self.tracked_target(\n",
    "                target=target, points_prev=points_prev, points_cur=points_cur, H=H, quad=quad\n",
    "            )\n",
    "            tracked.append(track)\n",
    "\n",
    "        tracked.sort(key=lambda x: len(x.points_prev), reverse=True)\n",
    "        return tracked\n",
    "\n",
    "    # Detect features in the selected ROIs and return the keypoints and descriptors\n",
    "    def detect_features(self, frame):\n",
    "        keypoints, descriptors = self.feature_detector.detectAndCompute(frame, None)\n",
    "        \n",
    "        if descriptors is None: descriptors = []\n",
    "        return keypoints, descriptors\n",
    "\n",
    "    # Function to clear all the existing targets\n",
    "    def clear_targets(self):\n",
    "        self.feature_matcher.clear()\n",
    "        self.tracking_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ROISelector(object):\n",
    "    def __init__(self, win_name, init_frame, callback_func):\n",
    "        self.callback_func = callback_func\n",
    "        self.selected_rect = None\n",
    "        self.drag_start = None\n",
    "        self.tracking_state = 0\n",
    "        event_params = {\"frame\": init_frame}\n",
    "        cv2.namedWindow(win_name)\n",
    "        cv2.setMouseCallback(win_name, self.mouse_event, event_params)\n",
    "\n",
    "    def mouse_event(self, event, x, y, flags, param):\n",
    "        x, y = np.int16([x, y])\n",
    "\n",
    "        # Detecting the mouse button down event\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.drag_start = (x, y)\n",
    "            self.tracking_state = 0\n",
    "\n",
    "        if self.drag_start:\n",
    "            if event == cv2.EVENT_MOUSEMOVE:\n",
    "                h, w = param[\"frame\"].shape[:2]\n",
    "                xo, yo = self.drag_start\n",
    "                x0, y0 = np.maximum(0, np.minimum([xo, yo], [x, y]))\n",
    "                x1, y1 = np.minimum([w, h], np.maximum([xo, yo], [x, y]))\n",
    "                self.selected_rect = None\n",
    "\n",
    "                if x1 - x0 > 0 and y1 - y0 > 0: self.selected_rect = (x0, y0, x1, y1)\n",
    "\n",
    "            elif event == cv2.EVENT_LBUTTONUP:\n",
    "                self.drag_start = None\n",
    "                if self.selected_rect is not None:\n",
    "                    self.callback_func(self.selected_rect)\n",
    "                    self.selected_rect = None\n",
    "                    self.tracking_state = 1\n",
    "\n",
    "    def draw_rect(self, img, rect):\n",
    "        if not rect: return False\n",
    "        x_start, y_start, x_end, y_end = rect\n",
    "        cv2.rectangle(img, (x_start, y_start), (x_end, y_end), (0, 255, 0), 2)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VideoHandler(object):\n",
    "    def __init__(self, scaling_factor, win_name):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.pose_tracker = PoseEstimator()\n",
    "        self.win_name = win_name\n",
    "        self.scaling_factor = scaling_factor\n",
    "\n",
    "        ret, frame = self.cap.read()\n",
    "        self.rect = None\n",
    "        self.frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "        self.roi_selector = ROISelector(win_name, self.frame, self.set_rect)\n",
    "\n",
    "    def set_rect(self, rect):\n",
    "        self.rect = rect\n",
    "        self.pose_tracker.add_target(self.frame, rect)\n",
    "\n",
    "    def start(self):\n",
    "        paused = False\n",
    "        while True:\n",
    "            if not paused or self.frame is None:\n",
    "                ret, frame = self.cap.read()\n",
    "                if frame is None: break\n",
    "                \n",
    "                frame = cv2.flip(frame, 1)\n",
    "                scaling_factor = self.scaling_factor\n",
    "                frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "                self.frame = frame.copy()\n",
    "\n",
    "            img = self.frame.copy()\n",
    "            if not paused and self.rect is not None:\n",
    "                tracked = self.pose_tracker.track_target(self.frame)\n",
    "                for item in tracked:\n",
    "                    cv2.polylines(img, [np.int32(item.quad)], True, (0, 0, 255), 2)\n",
    "                    for (x, y) in np.int32(item.points_cur): cv2.circle(img, (x, y), 2, (255, 0, 0))\n",
    "\n",
    "            self.roi_selector.draw_rect(img, self.rect)\n",
    "            cv2.imshow(self.win_name, img)\n",
    "            ch = cv2.waitKey(1)\n",
    "            if ch & 255 == ord(' '): paused = not paused\n",
    "            if ch & 255 == ord('c'): self.pose_tracker.clear_targets()\n",
    "            if ch & 255 == ord('q'): break\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VideoHandler(1.0, 'Tracker')\n",
    "v.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
